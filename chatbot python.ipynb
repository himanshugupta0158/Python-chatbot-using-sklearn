{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e26344c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eab99b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\himan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\himan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\himan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing and reading corpus(training data)\n",
    "f = open('chatbot.txt', 'r', errors='ignore')\n",
    "raw_doc = f.read()\n",
    "raw_doc = raw_doc.lower() #converts text into lowercase\n",
    "nltk.download('punkt') # Using the punkt toeknizer\n",
    "nltk.download('wordnet') # Using the Wordnet dictionary\n",
    "nltk.download('omw-1.4')\n",
    "sent_tokens = nltk.sent_tokenize(raw_doc) #Converts doc to list of sentences\n",
    "word_tokens = nltk.word_tokenize(raw_doc) #Con verts doc to list of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6412e493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what do you mean by data?',\n",
       " 'in computing, data is information that has been translated into a form that is efficient for movement or processing.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6763aaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what', 'do']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08c1717",
   "metadata": {},
   "source": [
    "### Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d08d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "# WordNet is a semantically-oriented dictionary of English included in NLTK\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d873c9c7",
   "metadata": {},
   "source": [
    "### Defining the greeting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b945a600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.22.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\himan\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ff7029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GREET_INPUTS = (\"hello\", \"hi\",\"greetings\",\"sup\",\"what's up\", \"hay\")\n",
    "GREET_RESPONSES = [\"hi\",\"hey\",\"*nods*\",\"hi there\",\"hello\",\"I am glad! You are talking to me\"]\n",
    "\n",
    "OTHER_INPUTS = {\n",
    "    \"how are you?\" : \"I am good, how are you?\",\n",
    "    \"how are you\" : \"I am good, how are you?\",\n",
    "    \"I am good\" : \"I am happy about that :>\",\n",
    "    \"I am good too\" : \"I am happy about that :>\"\n",
    "}\n",
    "\n",
    "def greet(sentence):\n",
    "    \n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREET_INPUTS:\n",
    "            return random.choice(GREET_RESPONSES)\n",
    "#         elif word.lower() in OTHER_INPUTS.keys():\n",
    "#             return OTHER_INPUTS[str(word.lower())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37588872",
   "metadata": {},
   "source": [
    "### Response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e886ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.9.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.22.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.31.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\himan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\himan\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0761a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer #Term freqency\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d75b0e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    robo1_response = ''\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    idx = vals.argsort()[0][-2]\n",
    "    flat = vals.flatten()\n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "    if req_tfidf==0:\n",
    "        robo1_response = robo1_response+\"I am sorry! I don't understand you\"\n",
    "        return robo1_response\n",
    "    else:\n",
    "        robo1_response = robo1_response+sent_tokens[idx]\n",
    "        return robo1_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f36ec7e",
   "metadata": {},
   "source": [
    "### Defining conversation start/end protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "511450d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: My name is HimanshuFirstBot. Let's have a conversation! Also, if you want to exist any time, just type 'Bye' !\n",
      "hi\n",
      "Bot: hi there\n",
      "scientists\n",
      "Bot: why become a data scientist?\n",
      "do not\n",
      "Bot: I am sorry! I don't understand you\n",
      "do\n",
      "Bot: I am sorry! I don't understand you\n",
      "boss\n",
      "Bot: I am sorry! I don't understand you\n",
      "stupid\n",
      "Bot: I am sorry! I don't understand you\n",
      "just\n",
      "Bot: I am sorry! I don't understand you\n",
      "risk\n",
      "Bot: for example, finance companies can use a customerâ€™s banking and bill-paying history to assess creditworthiness and loan risk.\n",
      "learn\n",
      "Bot: prerequisites for data science\n",
      "here are some of the technical concepts you should know about before starting to learn what is data science.\n",
      "bye\n",
      "Bot: GoodBye! Take care <3\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"Bot: My name is HimanshuFirstBot. Let's have a conversation! Also, if you want to exist any time, just type 'Bye' !\")\n",
    "while flag==True:\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if user_response != 'bye':\n",
    "        if user_response=='thanks' or user_response=='thank you':\n",
    "            flag=False\n",
    "            print(\"Bot: You are welcome\")\n",
    "        else:\n",
    "            if greet(user_response)!= None:\n",
    "                print(\"Bot: \"+greet(user_response))\n",
    "            else:\n",
    "                sent_tokens.append(user_response)\n",
    "                word_tokens = word_tokens+nltk.word_tokenize(user_response)\n",
    "                final_words = list(set(word_tokens))\n",
    "                print(\"Bot: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"Bot: GoodBye! Take care <3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b82c4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
